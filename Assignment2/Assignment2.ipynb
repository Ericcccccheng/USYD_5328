{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iEsnVn6G-uNn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 关闭 TensorFlow 警告日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uqvv1PPH9DBV",
    "outputId": "1018b8e9-8895-4af2-e78d-414ece43d186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 784) (18000,) (3000, 784) (3000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "dataset = np.load(r\"C:\\Users\\Maomao Gao\\Desktop\\5328ass2\\datasets\\FashionMNIST0.3.npz\")\n",
    "Xtr, Str = dataset[\"Xtr\"], dataset[\"Str\"]\n",
    "Xts, Yts = dataset[\"Xts\"], dataset[\"Yts\"]\n",
    "\n",
    "print(Xtr.shape, Str.shape, Xts.shape, Yts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lbxN5QYA9QMZ"
   },
   "outputs": [],
   "source": [
    "# transition matrix (已知)\n",
    "T = np.array([\n",
    "    [0.7, 0.3, 0.0],\n",
    "    [0.0, 0.7, 0.3],\n",
    "    [0.3, 0.0, 0.7]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(loss, input_shape, num_classes, T):\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z62xamdN-DE9"
   },
   "outputs": [],
   "source": [
    "def forward_correction_loss(T):\n",
    "    T = tf.constant(T, dtype=tf.float32)\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred_corrected = tf.matmul(y_pred, T)\n",
    "        y_pred_corrected = tf.clip_by_value(y_pred_corrected, 1e-7, 1.0)\n",
    "        return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred_corrected))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkadAwKv8hF6",
    "outputId": "ceb512c0-47dd-41dc-8335-9ff22ad9c378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Run 1/1\n",
      "Epoch 1/10\n",
      "113/113 - 4s - loss: 0.6864 - accuracy: 0.6756 - val_loss: 0.6528 - val_accuracy: 0.6861 - 4s/epoch - 39ms/step\n",
      "Epoch 2/10\n",
      "113/113 - 3s - loss: 0.6537 - accuracy: 0.6841 - val_loss: 0.6492 - val_accuracy: 0.6892 - 3s/epoch - 23ms/step\n",
      "Epoch 3/10\n",
      "113/113 - 3s - loss: 0.6470 - accuracy: 0.6865 - val_loss: 0.6449 - val_accuracy: 0.6911 - 3s/epoch - 25ms/step\n",
      "Epoch 4/10\n",
      "113/113 - 3s - loss: 0.6379 - accuracy: 0.6892 - val_loss: 0.6378 - val_accuracy: 0.6919 - 3s/epoch - 23ms/step\n",
      "Epoch 5/10\n",
      "113/113 - 2s - loss: 0.6348 - accuracy: 0.6906 - val_loss: 0.6429 - val_accuracy: 0.6914 - 2s/epoch - 22ms/step\n",
      "Epoch 6/10\n",
      "113/113 - 3s - loss: 0.6294 - accuracy: 0.6919 - val_loss: 0.6354 - val_accuracy: 0.6922 - 3s/epoch - 22ms/step\n",
      "Epoch 7/10\n",
      "113/113 - 3s - loss: 0.6309 - accuracy: 0.6922 - val_loss: 0.6368 - val_accuracy: 0.6900 - 3s/epoch - 23ms/step\n",
      "Epoch 8/10\n",
      "113/113 - 2s - loss: 0.6258 - accuracy: 0.6934 - val_loss: 0.6406 - val_accuracy: 0.6892 - 2s/epoch - 22ms/step\n",
      "Epoch 9/10\n",
      "113/113 - 3s - loss: 0.6224 - accuracy: 0.6952 - val_loss: 0.6338 - val_accuracy: 0.6936 - 3s/epoch - 22ms/step\n",
      "Epoch 10/10\n",
      "113/113 - 2s - loss: 0.6211 - accuracy: 0.6963 - val_loss: 0.6349 - val_accuracy: 0.6914 - 2s/epoch - 21ms/step\n",
      "✅ Test accuracy = 0.9850\n",
      "\n",
      "📊 Final Performance (10 runs):\n",
      "Mean Test Accuracy: 0.9850\n",
      "Standard Deviation: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 记录多次结果\n",
    "# num_runs = 10\n",
    "num_runs = 1 # for quickly testing the implement.\n",
    "test_accuracies = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n🔁 Run {run+1}/{num_runs}\")\n",
    "\n",
    "    # 每次随机划分数据\n",
    "    X_train, X_val, S_train, S_val = train_test_split(\n",
    "        Xtr, Str, test_size=0.2, stratify=Str, random_state=run\n",
    "    )\n",
    "\n",
    "    # 归一化\n",
    "    X_train = X_train.astype(\"float32\") / 255.0\n",
    "    X_val = X_val.astype(\"float32\") / 255.0\n",
    "    X_test = Xts.astype(\"float32\") / 255.0\n",
    "\n",
    "    # One-hot 编码\n",
    "    S_train_oh = to_categorical(S_train, num_classes=3)\n",
    "    S_val_oh   = to_categorical(S_val, num_classes=3)   # ✅ 验证集\n",
    "    Y_test_oh  = to_categorical(Yts, num_classes=3)\n",
    "\n",
    "    # 创建 Forward Learning模型\n",
    "    model = training_model(loss=forward_correction_loss(T), input_shape=X_train.shape[1:], num_classes=3, T=T)\n",
    "\n",
    "    # 训练\n",
    "    model.fit(\n",
    "    X_train, S_train_oh,\n",
    "    validation_data=(X_val, S_val_oh),  # ← 用于早停或监控验证集\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "    # 在测试集上评估\n",
    "    loss, acc = model.evaluate(X_test, Y_test_oh, verbose=0)\n",
    "    test_accuracies.append(acc)\n",
    "    print(f\"✅ Test accuracy = {acc:.4f}\")\n",
    "\n",
    "# 计算平均值和标准差\n",
    "mean_acc = np.mean(test_accuracies)\n",
    "std_acc = np.std(test_accuracies)\n",
    "\n",
    "print(\"\\n📊 Final Performance (10 runs):\")\n",
    "print(f\"Mean Test Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation: {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.32432432 -0.56756757  0.24324324]\n",
      " [ 0.24324324  1.32432432 -0.56756757]\n",
      " [-0.56756757  0.24324324  1.32432432]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linalg.pinv(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.32432432 -0.56756757  0.24324324]\n",
      " [ 0.24324324  1.32432432 -0.56756757]\n",
      " [-0.56756757  0.24324324  1.32432432]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linalg.inv(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_correction_loss(T):\n",
    "    T = tf.constant(T, dtype=tf.float32)\n",
    "    # T_inv = tf.linalg.inv(T)\n",
    "    T_inv = tf.linalg.pinv(T)\n",
    "    # 用伪逆矩阵计算替换逆矩阵计算，以使结果更加稳定，缓解逆矩阵计算过程中带来的真实标签预测向量不是概率的问题（虽然加和为1，但是有负的，还有大于1的）\n",
    "    # 但本例子求出来两个计算结果一样。这个问题也仍然存在。\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_corrected = tf.matmul(y_true, T_inv)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n",
    "        return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true_corrected, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Run 1/1\n",
      "Epoch 1/10\n",
      "113/113 - 3s - loss: 0.2009 - accuracy: 0.6697 - val_loss: -6.7740e-03 - val_accuracy: 0.6831 - 3s/epoch - 30ms/step\n",
      "Epoch 2/10\n",
      "113/113 - 2s - loss: 0.0982 - accuracy: 0.6803 - val_loss: -2.4639e-03 - val_accuracy: 0.6825 - 2s/epoch - 20ms/step\n",
      "Epoch 3/10\n",
      "113/113 - 2s - loss: 0.0986 - accuracy: 0.6782 - val_loss: 0.0086 - val_accuracy: 0.6872 - 2s/epoch - 19ms/step\n",
      "Epoch 4/10\n",
      "113/113 - 2s - loss: 0.0125 - accuracy: 0.6837 - val_loss: -7.2837e-03 - val_accuracy: 0.6850 - 2s/epoch - 19ms/step\n",
      "Epoch 5/10\n",
      "113/113 - 2s - loss: -3.4413e-02 - accuracy: 0.6820 - val_loss: 1.1399e-04 - val_accuracy: 0.6864 - 2s/epoch - 20ms/step\n",
      "Epoch 6/10\n",
      "113/113 - 2s - loss: -1.2384e-02 - accuracy: 0.6776 - val_loss: 0.0210 - val_accuracy: 0.6792 - 2s/epoch - 19ms/step\n",
      "Epoch 7/10\n",
      "113/113 - 2s - loss: -9.2740e-02 - accuracy: 0.6818 - val_loss: -1.3190e-02 - val_accuracy: 0.6847 - 2s/epoch - 19ms/step\n",
      "Epoch 8/10\n",
      "113/113 - 2s - loss: -9.1506e-02 - accuracy: 0.6822 - val_loss: 0.1301 - val_accuracy: 0.6544 - 2s/epoch - 20ms/step\n",
      "Epoch 9/10\n",
      "113/113 - 2s - loss: -1.3039e-01 - accuracy: 0.6831 - val_loss: 0.1791 - val_accuracy: 0.6572 - 2s/epoch - 20ms/step\n",
      "Epoch 10/10\n",
      "113/113 - 2s - loss: -2.1320e-01 - accuracy: 0.6856 - val_loss: 0.0219 - val_accuracy: 0.6853 - 2s/epoch - 20ms/step\n",
      "✅ Test accuracy (wrong) = 0.9570\n",
      "94/94 [==============================] - 1s 8ms/step\n",
      "✅ Corrected Test Accuracy (using T⁻¹, correct): 0.9627\n",
      "\n",
      "📊 Final Performance (10 runs):\n",
      "Mean Test Accuracy: 0.9598\n",
      "Standard Deviation: 0.0028\n"
     ]
    }
   ],
   "source": [
    "# 记录多次结果\n",
    "# num_runs = 10\n",
    "num_runs = 1 # for quickly testing the implement.\n",
    "test_accuracies = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\n🔁 Run {run+1}/{num_runs}\")\n",
    "\n",
    "    # 每次随机划分数据\n",
    "    X_train, X_val, S_train, S_val = train_test_split(\n",
    "        Xtr, Str, test_size=0.2, stratify=Str, random_state=run\n",
    "    )\n",
    "\n",
    "    # 归一化\n",
    "    X_train = X_train.astype(\"float32\") / 255.0\n",
    "    X_val = X_val.astype(\"float32\") / 255.0\n",
    "    X_test = Xts.astype(\"float32\") / 255.0\n",
    "\n",
    "    # One-hot 编码\n",
    "    S_train_oh = to_categorical(S_train, num_classes=3)\n",
    "    S_val_oh   = to_categorical(S_val, num_classes=3)   # ✅ 验证集\n",
    "    Y_test_oh  = to_categorical(Yts, num_classes=3)\n",
    "\n",
    "    # 创建 Backward Learning模型\n",
    "    model = training_model(loss=backward_correction_loss(T), input_shape=X_train.shape[1:], num_classes=3, T=T)\n",
    "\n",
    "    # 训练\n",
    "    model.fit(\n",
    "    X_train, S_train_oh,\n",
    "    validation_data=(X_val, S_val_oh),  # ← 用于早停或监控验证集\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "    # 原来忘了输出结果左乘T逆矩阵了 - 在测试集上评估\n",
    "    # 结果很好，因为此时模型已经学到了真实的标签分布\n",
    "    loss, acc = model.evaluate(X_test, Y_test_oh, verbose=0)\n",
    "    test_accuracies.append(acc)\n",
    "    print(f\"✅ Test accuracy (wrong) = {acc:.4f}\")\n",
    "\n",
    "    # 现在补上了 - 在测试集上评估 - 原作者的实现也没有在这里修正。\n",
    "    # 结果反而差了，可能乘上之后对结果修正过头了\n",
    "    y_pred_noisy = model.predict(X_test)\n",
    "    T_inv = np.linalg.pinv(T)\n",
    "    y_pred_clean = np.dot(y_pred_noisy, T_inv)\n",
    "    y_pred_clean = np.clip(y_pred_clean, 1e-7, 1.0)\n",
    "    y_pred_clean /= np.sum(y_pred_clean, axis=1, keepdims=True)\n",
    "    \n",
    "    y_pred_label = np.argmax(y_pred_clean, axis=1)\n",
    "    true_label = np.argmax(Y_test_oh, axis=1)\n",
    "    acc_clean = np.mean(y_pred_label == true_label)\n",
    "    print(f\"✅ Corrected Test Accuracy (using T⁻¹, correct): {acc_clean:.4f}\")\n",
    "    test_accuracies.append(acc_clean)\n",
    "\n",
    "# 计算平均值和标准差\n",
    "mean_acc = np.mean(test_accuracies)\n",
    "std_acc = np.std(test_accuracies)\n",
    "\n",
    "print(\"\\n📊 Final Performance (10 runs):\")\n",
    "print(f\"Mean Test Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation: {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程中loss不稳定，说明这个方法鲁棒性弱于FL。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "5328_A1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
