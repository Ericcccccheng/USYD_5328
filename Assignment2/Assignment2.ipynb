{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iEsnVn6G-uNn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # å…³é—­ TensorFlow è­¦å‘Šæ—¥å¿—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uqvv1PPH9DBV",
    "outputId": "1018b8e9-8895-4af2-e78d-414ece43d186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 784) (18000,) (3000, 784) (3000,)\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ•°æ®\n",
    "dataset = np.load(r\"C:\\Users\\Maomao Gao\\Desktop\\5328ass2\\datasets\\FashionMNIST0.3.npz\")\n",
    "Xtr, Str = dataset[\"Xtr\"], dataset[\"Str\"]\n",
    "Xts, Yts = dataset[\"Xts\"], dataset[\"Yts\"]\n",
    "\n",
    "print(Xtr.shape, Str.shape, Xts.shape, Yts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lbxN5QYA9QMZ"
   },
   "outputs": [],
   "source": [
    "# transition matrix (å·²çŸ¥)\n",
    "T = np.array([\n",
    "    [0.7, 0.3, 0.0],\n",
    "    [0.0, 0.7, 0.3],\n",
    "    [0.3, 0.0, 0.7]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(loss, input_shape, num_classes, T):\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z62xamdN-DE9"
   },
   "outputs": [],
   "source": [
    "def forward_correction_loss(T):\n",
    "    T = tf.constant(T, dtype=tf.float32)\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred_corrected = tf.matmul(y_pred, T)\n",
    "        y_pred_corrected = tf.clip_by_value(y_pred_corrected, 1e-7, 1.0)\n",
    "        return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true, y_pred_corrected))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkadAwKv8hF6",
    "outputId": "ceb512c0-47dd-41dc-8335-9ff22ad9c378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Run 1/1\n",
      "Epoch 1/10\n",
      "113/113 - 4s - loss: 0.6864 - accuracy: 0.6756 - val_loss: 0.6528 - val_accuracy: 0.6861 - 4s/epoch - 39ms/step\n",
      "Epoch 2/10\n",
      "113/113 - 3s - loss: 0.6537 - accuracy: 0.6841 - val_loss: 0.6492 - val_accuracy: 0.6892 - 3s/epoch - 23ms/step\n",
      "Epoch 3/10\n",
      "113/113 - 3s - loss: 0.6470 - accuracy: 0.6865 - val_loss: 0.6449 - val_accuracy: 0.6911 - 3s/epoch - 25ms/step\n",
      "Epoch 4/10\n",
      "113/113 - 3s - loss: 0.6379 - accuracy: 0.6892 - val_loss: 0.6378 - val_accuracy: 0.6919 - 3s/epoch - 23ms/step\n",
      "Epoch 5/10\n",
      "113/113 - 2s - loss: 0.6348 - accuracy: 0.6906 - val_loss: 0.6429 - val_accuracy: 0.6914 - 2s/epoch - 22ms/step\n",
      "Epoch 6/10\n",
      "113/113 - 3s - loss: 0.6294 - accuracy: 0.6919 - val_loss: 0.6354 - val_accuracy: 0.6922 - 3s/epoch - 22ms/step\n",
      "Epoch 7/10\n",
      "113/113 - 3s - loss: 0.6309 - accuracy: 0.6922 - val_loss: 0.6368 - val_accuracy: 0.6900 - 3s/epoch - 23ms/step\n",
      "Epoch 8/10\n",
      "113/113 - 2s - loss: 0.6258 - accuracy: 0.6934 - val_loss: 0.6406 - val_accuracy: 0.6892 - 2s/epoch - 22ms/step\n",
      "Epoch 9/10\n",
      "113/113 - 3s - loss: 0.6224 - accuracy: 0.6952 - val_loss: 0.6338 - val_accuracy: 0.6936 - 3s/epoch - 22ms/step\n",
      "Epoch 10/10\n",
      "113/113 - 2s - loss: 0.6211 - accuracy: 0.6963 - val_loss: 0.6349 - val_accuracy: 0.6914 - 2s/epoch - 21ms/step\n",
      "âœ… Test accuracy = 0.9850\n",
      "\n",
      "ğŸ“Š Final Performance (10 runs):\n",
      "Mean Test Accuracy: 0.9850\n",
      "Standard Deviation: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# è®°å½•å¤šæ¬¡ç»“æœ\n",
    "# num_runs = 10\n",
    "num_runs = 1 # for quickly testing the implement.\n",
    "test_accuracies = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\nğŸ” Run {run+1}/{num_runs}\")\n",
    "\n",
    "    # æ¯æ¬¡éšæœºåˆ’åˆ†æ•°æ®\n",
    "    X_train, X_val, S_train, S_val = train_test_split(\n",
    "        Xtr, Str, test_size=0.2, stratify=Str, random_state=run\n",
    "    )\n",
    "\n",
    "    # å½’ä¸€åŒ–\n",
    "    X_train = X_train.astype(\"float32\") / 255.0\n",
    "    X_val = X_val.astype(\"float32\") / 255.0\n",
    "    X_test = Xts.astype(\"float32\") / 255.0\n",
    "\n",
    "    # One-hot ç¼–ç \n",
    "    S_train_oh = to_categorical(S_train, num_classes=3)\n",
    "    S_val_oh   = to_categorical(S_val, num_classes=3)   # âœ… éªŒè¯é›†\n",
    "    Y_test_oh  = to_categorical(Yts, num_classes=3)\n",
    "\n",
    "    # åˆ›å»º Forward Learningæ¨¡å‹\n",
    "    model = training_model(loss=forward_correction_loss(T), input_shape=X_train.shape[1:], num_classes=3, T=T)\n",
    "\n",
    "    # è®­ç»ƒ\n",
    "    model.fit(\n",
    "    X_train, S_train_oh,\n",
    "    validation_data=(X_val, S_val_oh),  # â† ç”¨äºæ—©åœæˆ–ç›‘æ§éªŒè¯é›†\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "    loss, acc = model.evaluate(X_test, Y_test_oh, verbose=0)\n",
    "    test_accuracies.append(acc)\n",
    "    print(f\"âœ… Test accuracy = {acc:.4f}\")\n",
    "\n",
    "# è®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®\n",
    "mean_acc = np.mean(test_accuracies)\n",
    "std_acc = np.std(test_accuracies)\n",
    "\n",
    "print(\"\\nğŸ“Š Final Performance (10 runs):\")\n",
    "print(f\"Mean Test Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation: {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.32432432 -0.56756757  0.24324324]\n",
      " [ 0.24324324  1.32432432 -0.56756757]\n",
      " [-0.56756757  0.24324324  1.32432432]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linalg.pinv(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.32432432 -0.56756757  0.24324324]\n",
      " [ 0.24324324  1.32432432 -0.56756757]\n",
      " [-0.56756757  0.24324324  1.32432432]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linalg.inv(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_correction_loss(T):\n",
    "    T = tf.constant(T, dtype=tf.float32)\n",
    "    # T_inv = tf.linalg.inv(T)\n",
    "    T_inv = tf.linalg.pinv(T)\n",
    "    # ç”¨ä¼ªé€†çŸ©é˜µè®¡ç®—æ›¿æ¢é€†çŸ©é˜µè®¡ç®—ï¼Œä»¥ä½¿ç»“æœæ›´åŠ ç¨³å®šï¼Œç¼“è§£é€†çŸ©é˜µè®¡ç®—è¿‡ç¨‹ä¸­å¸¦æ¥çš„çœŸå®æ ‡ç­¾é¢„æµ‹å‘é‡ä¸æ˜¯æ¦‚ç‡çš„é—®é¢˜ï¼ˆè™½ç„¶åŠ å’Œä¸º1ï¼Œä½†æ˜¯æœ‰è´Ÿçš„ï¼Œè¿˜æœ‰å¤§äº1çš„ï¼‰\n",
    "    # ä½†æœ¬ä¾‹å­æ±‚å‡ºæ¥ä¸¤ä¸ªè®¡ç®—ç»“æœä¸€æ ·ã€‚è¿™ä¸ªé—®é¢˜ä¹Ÿä»ç„¶å­˜åœ¨ã€‚\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_corrected = tf.matmul(y_true, T_inv)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n",
    "        return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true_corrected, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Run 1/1\n",
      "Epoch 1/10\n",
      "113/113 - 3s - loss: 0.2009 - accuracy: 0.6697 - val_loss: -6.7740e-03 - val_accuracy: 0.6831 - 3s/epoch - 30ms/step\n",
      "Epoch 2/10\n",
      "113/113 - 2s - loss: 0.0982 - accuracy: 0.6803 - val_loss: -2.4639e-03 - val_accuracy: 0.6825 - 2s/epoch - 20ms/step\n",
      "Epoch 3/10\n",
      "113/113 - 2s - loss: 0.0986 - accuracy: 0.6782 - val_loss: 0.0086 - val_accuracy: 0.6872 - 2s/epoch - 19ms/step\n",
      "Epoch 4/10\n",
      "113/113 - 2s - loss: 0.0125 - accuracy: 0.6837 - val_loss: -7.2837e-03 - val_accuracy: 0.6850 - 2s/epoch - 19ms/step\n",
      "Epoch 5/10\n",
      "113/113 - 2s - loss: -3.4413e-02 - accuracy: 0.6820 - val_loss: 1.1399e-04 - val_accuracy: 0.6864 - 2s/epoch - 20ms/step\n",
      "Epoch 6/10\n",
      "113/113 - 2s - loss: -1.2384e-02 - accuracy: 0.6776 - val_loss: 0.0210 - val_accuracy: 0.6792 - 2s/epoch - 19ms/step\n",
      "Epoch 7/10\n",
      "113/113 - 2s - loss: -9.2740e-02 - accuracy: 0.6818 - val_loss: -1.3190e-02 - val_accuracy: 0.6847 - 2s/epoch - 19ms/step\n",
      "Epoch 8/10\n",
      "113/113 - 2s - loss: -9.1506e-02 - accuracy: 0.6822 - val_loss: 0.1301 - val_accuracy: 0.6544 - 2s/epoch - 20ms/step\n",
      "Epoch 9/10\n",
      "113/113 - 2s - loss: -1.3039e-01 - accuracy: 0.6831 - val_loss: 0.1791 - val_accuracy: 0.6572 - 2s/epoch - 20ms/step\n",
      "Epoch 10/10\n",
      "113/113 - 2s - loss: -2.1320e-01 - accuracy: 0.6856 - val_loss: 0.0219 - val_accuracy: 0.6853 - 2s/epoch - 20ms/step\n",
      "âœ… Test accuracy (wrong) = 0.9570\n",
      "94/94 [==============================] - 1s 8ms/step\n",
      "âœ… Corrected Test Accuracy (using Tâ»Â¹, correct): 0.9627\n",
      "\n",
      "ğŸ“Š Final Performance (10 runs):\n",
      "Mean Test Accuracy: 0.9598\n",
      "Standard Deviation: 0.0028\n"
     ]
    }
   ],
   "source": [
    "# è®°å½•å¤šæ¬¡ç»“æœ\n",
    "# num_runs = 10\n",
    "num_runs = 1 # for quickly testing the implement.\n",
    "test_accuracies = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"\\nğŸ” Run {run+1}/{num_runs}\")\n",
    "\n",
    "    # æ¯æ¬¡éšæœºåˆ’åˆ†æ•°æ®\n",
    "    X_train, X_val, S_train, S_val = train_test_split(\n",
    "        Xtr, Str, test_size=0.2, stratify=Str, random_state=run\n",
    "    )\n",
    "\n",
    "    # å½’ä¸€åŒ–\n",
    "    X_train = X_train.astype(\"float32\") / 255.0\n",
    "    X_val = X_val.astype(\"float32\") / 255.0\n",
    "    X_test = Xts.astype(\"float32\") / 255.0\n",
    "\n",
    "    # One-hot ç¼–ç \n",
    "    S_train_oh = to_categorical(S_train, num_classes=3)\n",
    "    S_val_oh   = to_categorical(S_val, num_classes=3)   # âœ… éªŒè¯é›†\n",
    "    Y_test_oh  = to_categorical(Yts, num_classes=3)\n",
    "\n",
    "    # åˆ›å»º Backward Learningæ¨¡å‹\n",
    "    model = training_model(loss=backward_correction_loss(T), input_shape=X_train.shape[1:], num_classes=3, T=T)\n",
    "\n",
    "    # è®­ç»ƒ\n",
    "    model.fit(\n",
    "    X_train, S_train_oh,\n",
    "    validation_data=(X_val, S_val_oh),  # â† ç”¨äºæ—©åœæˆ–ç›‘æ§éªŒè¯é›†\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "    # åŸæ¥å¿˜äº†è¾“å‡ºç»“æœå·¦ä¹˜Té€†çŸ©é˜µäº† - åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\n",
    "    # ç»“æœå¾ˆå¥½ï¼Œå› ä¸ºæ­¤æ—¶æ¨¡å‹å·²ç»å­¦åˆ°äº†çœŸå®çš„æ ‡ç­¾åˆ†å¸ƒ\n",
    "    loss, acc = model.evaluate(X_test, Y_test_oh, verbose=0)\n",
    "    test_accuracies.append(acc)\n",
    "    print(f\"âœ… Test accuracy (wrong) = {acc:.4f}\")\n",
    "\n",
    "    # ç°åœ¨è¡¥ä¸Šäº† - åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° - åŸä½œè€…çš„å®ç°ä¹Ÿæ²¡æœ‰åœ¨è¿™é‡Œä¿®æ­£ã€‚\n",
    "    # ç»“æœåè€Œå·®äº†ï¼Œå¯èƒ½ä¹˜ä¸Šä¹‹åå¯¹ç»“æœä¿®æ­£è¿‡å¤´äº†\n",
    "    y_pred_noisy = model.predict(X_test)\n",
    "    T_inv = np.linalg.pinv(T)\n",
    "    y_pred_clean = np.dot(y_pred_noisy, T_inv)\n",
    "    y_pred_clean = np.clip(y_pred_clean, 1e-7, 1.0)\n",
    "    y_pred_clean /= np.sum(y_pred_clean, axis=1, keepdims=True)\n",
    "    \n",
    "    y_pred_label = np.argmax(y_pred_clean, axis=1)\n",
    "    true_label = np.argmax(Y_test_oh, axis=1)\n",
    "    acc_clean = np.mean(y_pred_label == true_label)\n",
    "    print(f\"âœ… Corrected Test Accuracy (using Tâ»Â¹, correct): {acc_clean:.4f}\")\n",
    "    test_accuracies.append(acc_clean)\n",
    "\n",
    "# è®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®\n",
    "mean_acc = np.mean(test_accuracies)\n",
    "std_acc = np.std(test_accuracies)\n",
    "\n",
    "print(\"\\nğŸ“Š Final Performance (10 runs):\")\n",
    "print(f\"Mean Test Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation: {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®­ç»ƒè¿‡ç¨‹ä¸­lossä¸ç¨³å®šï¼Œè¯´æ˜è¿™ä¸ªæ–¹æ³•é²æ£’æ€§å¼±äºFLã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "5328_A1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
